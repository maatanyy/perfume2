"""í¬ë¡¤ë§ ì—”ì§„"""

import threading
from typing import List, Dict
from flask import current_app
from database import db
from app import create_app
from models.crawling_job import CrawlingJob
from models.crawling_log import CrawlingLog
from crawlers.crawler_factory import get_crawler, get_crawler_by_url
from utils.google_sheets import get_sheet_data, parse_sheet_data, extract_spreadsheet_id
import time
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed


class CrawlingEngine:
    """í¬ë¡¤ë§ ì—”ì§„ (Threading ë°©ì‹)"""

    def __init__(self):
        self.active_jobs = {}  # job_id -> thread
        self.job_cancelled = {}  # job_id -> bool
        self.app = None  # Flask ì•± ì¸ìŠ¤í„´ìŠ¤ ì €ì¥

    def set_app(self, app):
        """Flask ì•± ì„¤ì • (ìŠ¤ë ˆë“œì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´)"""
        self.app = app

    def start_crawling(self, job: CrawlingJob, spreadsheet_url: str, sheet_name: str):
        """í¬ë¡¤ë§ ì‘ì—… ì‹œì‘"""
        thread = threading.Thread(
            target=self._run_crawling,
            args=(job.id, spreadsheet_url, sheet_name),
            daemon=True,
        )
        self.active_jobs[job.id] = thread
        self.job_cancelled[job.id] = False
        thread.start()

    def cancel_job(self, job_id: int):
        """ì‘ì—… ì·¨ì†Œ"""
        self.job_cancelled[job_id] = True

    def _run_crawling(self, job_id: int, spreadsheet_url: str, sheet_name: str):
        """í¬ë¡¤ë§ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ)"""
        # Flask ì•± ì»¨í…ìŠ¤íŠ¸ ì„¤ì • (ìŠ¤ë ˆë“œì—ì„œëŠ” ìë™ìœ¼ë¡œ ì„¤ì •ë˜ì§€ ì•ŠìŒ)
        if self.app:
            with self.app.app_context():
                self._do_crawling(job_id, spreadsheet_url, sheet_name)
        else:
            # ì•±ì´ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ìƒˆë¡œ ìƒì„±
            app = create_app()
            with app.app_context():
                self._do_crawling(job_id, spreadsheet_url, sheet_name)

    def _do_crawling(self, job_id: int, spreadsheet_url: str, sheet_name: str):
        """ì‹¤ì œ í¬ë¡¤ë§ ì‘ì—… (ì•± ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ì‹¤í–‰)"""
        from utils.google_sheets import extract_gid_from_url

        job = CrawlingJob.query.get(job_id)
        if not job:
            return

        try:
            job.start()
            self._add_log(job_id, "INFO", f"í¬ë¡¤ë§ ì‹œì‘: {sheet_name}")

            # êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            self._add_log(job_id, "INFO", "êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„° ì½ê¸° ì¤‘...")
            spreadsheet_id = extract_spreadsheet_id(spreadsheet_url)
            if not spreadsheet_id:
                raise ValueError("êµ¬ê¸€ ì‹œíŠ¸ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # GID ì¶”ì¶œ (ì‹œíŠ¸ ID)
            gid = extract_gid_from_url(spreadsheet_url)

            values = get_sheet_data(spreadsheet_id, sheet_name, gid)
            products = parse_sheet_data(values)
            self._add_log(
                job_id, "INFO", f"êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ {len(products)}ê°œ ì œí’ˆ íŒŒì‹± ì™„ë£Œ"
            )

            if len(products) == 0:
                raise ValueError("í¬ë¡¤ë§í•  ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")

            job.total_items = len(products)
            job.processed_items = 0
            db.session.commit()

            self._add_log(job_id, "INFO", f"ì´ {len(products)}ê°œ ì œí’ˆ ë°œê²¬")

            # í¬ë¡¤ëŸ¬ ê°€ì ¸ì˜¤ê¸° (ì‚¬ì´íŠ¸ëª… ë˜ëŠ” URL ê¸°ë°˜)
            self._add_log(job_id, "INFO", f"í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”: {job.site_name}")
            crawler = get_crawler(job.site_name)
            if not crawler:
                # URLì—ì„œ ì‚¬ì´íŠ¸ ê°ì§€ ì‹œë„
                self._add_log(
                    job_id,
                    "WARNING",
                    "ì‚¬ì´íŠ¸ëª…ìœ¼ë¡œ í¬ë¡¤ëŸ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì—ì„œ ê°ì§€ ì‹œë„...",
                )
                if job.google_sheet_url:
                    # ì²« ë²ˆì§¸ ì œí’ˆ URLë¡œ ì‚¬ì´íŠ¸ ê°ì§€
                    if products and products[0].get("waffle", {}).get("url"):
                        first_url = products[0]["waffle"]["url"]
                        crawler = get_crawler_by_url(first_url)
                        if crawler:
                            self._add_log(job_id, "INFO", "URL ê¸°ë°˜ í¬ë¡¤ëŸ¬ ê°ì§€ ì„±ê³µ")

                if not crawler:
                    raise ValueError(f"{job.site_name} ì‚¬ì´íŠ¸ëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            results = []
            batch_size = 10  # ë°°ì¹˜ í¬ê¸°
            max_workers = 3  # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ë©”ëª¨ë¦¬ ìµœì í™”: 5 -> 3)

            for i in range(0, len(products), batch_size):
                if self.job_cancelled.get(job_id, False):
                    job.cancel()
                    self._add_log(job_id, "INFO", "í¬ë¡¤ë§ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    return

                batch = products[i : i + batch_size]
                batch_num = (i // batch_size) + 1
                total_batches = (len(products) + batch_size - 1) // batch_size
                self._add_log(
                    job_id,
                    "INFO",
                    f"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ì œí’ˆ)",
                )
                batch_results = []

                # ë³‘ë ¬ ì²˜ë¦¬ë¡œ í¬ë¡¤ë§
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_product = {
                        executor.submit(
                            self._crawl_product_safe,
                            product,
                            crawler,
                            job.site_name,
                            job_id,
                        ): product
                        for product in batch
                    }

                    for future in as_completed(future_to_product):
                        if self.job_cancelled.get(job_id, False):
                            break

                        try:
                            result = future.result()
                            batch_results.append(result)

                            # ì›Œì»¤ ìŠ¤ë ˆë“œì—ì„œ ìˆ˜ì§‘í•œ ë¡œê·¸ë¥¼ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ DBì— ì¶”ê°€
                            if "logs" in result:
                                for log_level, log_message in result["logs"]:
                                    self._add_log(job_id, log_level, log_message)
                                # ë¡œê·¸ë¥¼ DBì— ì¶”ê°€í•œ í›„ ê²°ê³¼ì—ì„œ ì œê±°
                                del result["logs"]

                        except Exception as e:
                            product = future_to_product[future]
                            self._add_log(
                                job_id,
                                "ERROR",
                                f'ì œí’ˆ í¬ë¡¤ë§ ì‹¤íŒ¨: {product["product_name"]} - {str(e)}',
                            )
                            batch_results.append(
                                {
                                    "product_id": product["product_id"],
                                    "product_name": product["product_name"],
                                    "timestamp": datetime.now().isoformat(),
                                    "prices": [],
                                    "error": str(e),
                                }
                            )

                results.extend(batch_results)

                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                processed = min(i + batch_size, len(products))
                job.update_progress(processed, len(products))
                self._add_log(
                    job_id,
                    "INFO",
                    f"ì§„í–‰ë¥ : {processed}/{len(products)} ({job.progress}%)",
                )

                if i + batch_size < len(products):
                    time.sleep(0.2)  # ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„ ë‹¨ì¶• (0.3 -> 0.2)

            # ê²°ê³¼ ì €ì¥ (Excel íŒŒì¼ ìƒì„±)
            result_file = self._save_results(job_id, results, job.site_name)
            if result_file:
                job.result_file = result_file
                db.session.commit()
                self._add_log(job_id, "INFO", f"ê²°ê³¼ íŒŒì¼ ì €ì¥: {result_file}")

            job.complete()
            self._add_log(job_id, "INFO", f"í¬ë¡¤ë§ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")

        except Exception as e:
            job.fail(str(e))
            self._add_log(job_id, "ERROR", f"í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}")
        finally:
            # ì‘ì—… ì™„ë£Œ í›„ ì •ë¦¬
            if job_id in self.active_jobs:
                del self.active_jobs[job_id]
            if job_id in self.job_cancelled:
                del self.job_cancelled[job_id]

    def _crawl_product(self, product: Dict, default_crawler, site_name: str) -> Dict:
        """ë‹¨ì¼ ì œí’ˆ í¬ë¡¤ë§ (URL ê¸°ë°˜ í¬ë¡¤ëŸ¬ ìë™ ì„ íƒ)"""
        result = {
            "product_id": product["product_id"],
            "product_name": product["product_name"],
            "timestamp": datetime.now().isoformat(),
            "prices": [],
            "logs": [],  # ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ì €ì¥ (ë‚˜ì¤‘ì— ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ DBì— ì¶”ê°€)
        }

        def get_crawler_for_url(url: str):
            """URLì— ë§ëŠ” í¬ë¡¤ëŸ¬ ë°˜í™˜"""
            url_crawler = get_crawler_by_url(url)
            selected_crawler = url_crawler if url_crawler else default_crawler
            crawler_name = selected_crawler.__class__.__name__
            result["logs"].append(
                (
                    "INFO",
                    f"ğŸ” [{url[:60]}...] â†’ {crawler_name}",
                )
            )
            return selected_crawler

        # ì œí’ˆëª…ì„ ì•ˆì „í•˜ê²Œ ì˜ë¼ë‚´ê¸° (UTF-8 ë³´ì¥)
        product_name = str(product.get("product_name", "Unknown"))
        if len(product_name) > 20:
            product_name_short = product_name[:20] + "..."
        else:
            product_name_short = product_name

        # Waffle í¬ë¡¤ë§
        if product.get("waffle") and product["waffle"].get("url"):
            url = product["waffle"]["url"]
            try:
                crawler = get_crawler_for_url(url)
                waffle_data = crawler.crawl_price(url)
                result["prices"].append({"seller": "waffle", **waffle_data})
                price_info = f"{waffle_data.get('ìƒí’ˆ ê°€ê²©', 'N/A')}ì›"
                result["logs"].append(
                    (
                        "INFO",
                        f"âœ“ {product_name_short} Waffle: {price_info}",
                    )
                )
            except Exception as e:
                result["logs"].append(
                    (
                        "ERROR",
                        f"âœ— {product_name_short} Waffle ì‹¤íŒ¨: {str(e)[:50]}",
                    )
                )
                result["prices"].append({"seller": "waffle", "error": str(e)})

        # ê²½ìŸì‚¬ í¬ë¡¤ë§
        for competitor in product.get("competitors", []):
            if competitor.get("url"):
                url = competitor["url"]
                seller_name = competitor["name"]
                try:
                    crawler = get_crawler_for_url(url)
                    comp_data = crawler.crawl_price(url)
                    result["prices"].append({"seller": seller_name, **comp_data})
                    price_info = f"{comp_data.get('ìƒí’ˆ ê°€ê²©', 'N/A')}ì›"
                    result["logs"].append(
                        (
                            "INFO",
                            f"âœ“ {product_name_short} {seller_name}: {price_info}",
                        )
                    )
                except Exception as e:
                    result["logs"].append(
                        (
                            "ERROR",
                            f"âœ— {product_name_short} {seller_name} ì‹¤íŒ¨: {str(e)[:50]}",
                        )
                    )
                    result["prices"].append({"seller": seller_name, "error": str(e)})

        return result

    def _crawl_product_safe(
        self, product: Dict, default_crawler, site_name: str, job_id: int
    ) -> Dict:
        """ì•ˆì „í•œ ì œí’ˆ í¬ë¡¤ë§ (ë³‘ë ¬ ì²˜ë¦¬ìš©, ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)"""
        try:
            return self._crawl_product(product, default_crawler, site_name)
        except Exception as e:
            product_name = str(product.get("product_name", "Unknown"))
            if len(product_name) > 20:
                product_name_short = product_name[:20] + "..."
            else:
                product_name_short = product_name

            return {
                "product_id": product["product_id"],
                "product_name": product["product_name"],
                "timestamp": datetime.now().isoformat(),
                "prices": [],
                "error": str(e),
                "logs": [
                    ("ERROR", f"âœ— {product_name_short} ì¹˜ëª…ì  ì˜¤ë¥˜: {str(e)[:50]}")
                ],
            }

    def _save_results(self, job_id: int, results: List[Dict], site_name: str) -> str:
        """ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥ (xlsxwriter ì‚¬ìš© - ì•ˆì •ì )"""
        try:
            import xlsxwriter
            import os

            # ê²°ê³¼ í´ë” ìƒì„±
            results_dir = "results"
            os.makedirs(results_dir, exist_ok=True)

            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{site_name}_ê°€ê²©ì¡°ì‚¬_{timestamp}.xlsx"
            filepath = os.path.join(results_dir, filename)

            # ì›Œí¬ë¶ ìƒì„±
            workbook = xlsxwriter.Workbook(filepath, {"strings_to_numbers": False})

            # í¬ë§· ì •ì˜
            header_format = workbook.add_format(
                {
                    "bold": True,
                    "bg_color": "#366092",
                    "font_color": "white",
                    "align": "center",
                    "valign": "vcenter",
                }
            )
            title_format = workbook.add_format({"bold": True, "font_size": 12})
            bold_format = workbook.add_format({"bold": True})
            bold_red_format = workbook.add_format({"bold": True, "font_color": "red"})

            # ì‹œíŠ¸1: ì „ì²´ ê²°ê³¼
            worksheet1 = workbook.add_worksheet("ì „ì²´ ê²°ê³¼")
            worksheet1.set_column("A:A", 20)
            worksheet1.set_column("B:B", 50)
            worksheet1.set_column("C:F", 15)

            row = 0
            for result in results:
                # ì œí’ˆ ì •ë³´
                worksheet1.write(
                    row, 0, f"ì œí’ˆëª…: {result['product_name']}", title_format
                )
                row += 1
                worksheet1.write(row, 0, f"ì œí’ˆID: {result['product_id']}")
                row += 1
                worksheet1.write(row, 0, f"ì¶”ì¶œ ì‹œê°„: {result['timestamp']}")
                row += 2

                # í—¤ë”
                headers = [
                    "íŒë§¤ì²˜",
                    "ìƒí’ˆ URL",
                    "ìƒí’ˆê°€ê²©",
                    "ë°°ì†¡ë¹„",
                    "ë°°ì†¡ë¹„ì—¬ë¶€",
                    "ìµœì¢…ê°€ê²©",
                ]
                for col, header in enumerate(headers):
                    worksheet1.write(row, col, header, header_format)
                row += 1

                # ë°ì´í„°
                for price in result.get("prices", []):
                    seller = (
                        "Waffle (ìš°ë¦¬íšŒì‚¬)"
                        if price["seller"] == "waffle"
                        else f"ê²½ìŸì‚¬ ({price['seller']})"
                    )
                    worksheet1.write_string(row, 0, seller)
                    worksheet1.write_string(row, 1, str(price.get("ìƒí’ˆ url", "N/A")))

                    # ê°€ê²© ë°ì´í„°
                    p_val = price.get("ìƒí’ˆ ê°€ê²©", "N/A")
                    if isinstance(p_val, (int, float)):
                        worksheet1.write_number(row, 2, p_val)
                    else:
                        worksheet1.write_string(row, 2, str(p_val))

                    s_val = price.get("ë°°ì†¡ë¹„", "N/A")
                    if isinstance(s_val, (int, float)):
                        worksheet1.write_number(row, 3, s_val)
                    else:
                        worksheet1.write_string(row, 3, str(s_val))

                    worksheet1.write_string(
                        row, 4, str(price.get("ë°°ì†¡ë¹„ ì—¬ë¶€", "N/A"))
                    )

                    f_val = price.get("ìµœì¢… ê°€ê²©", "N/A")
                    if isinstance(f_val, (int, float)):
                        worksheet1.write_number(row, 5, f_val)
                    else:
                        worksheet1.write_string(row, 5, str(f_val))

                    row += 1
                row += 2  # ë¹ˆ ì¤„

            # ì‹œíŠ¸2: ê°€ê²© ì—­ì „ í•­ëª©
            worksheet2 = workbook.add_worksheet("ê°€ê²© ì—­ì „ í•­ëª©")
            worksheet2.set_column("A:A", 20)
            worksheet2.set_column("B:B", 50)
            worksheet2.set_column("C:F", 15)
            worksheet2.set_column("G:G", 20)

            row = 0
            # '='ë¡œ ì‹œì‘í•˜ì§€ ì•Šë„ë¡ ë³€ê²½ (Excelì´ ìˆ˜ì‹ìœ¼ë¡œ ì˜¤ì¸í•˜ì§€ ì•Šë„ë¡)
            worksheet2.write_string(
                row, 0, "ã€ê°€ê²© ì—­ì „ í•­ëª© (ê²½ìŸì‚¬ê°€ ë” ì €ë ´í•œ ê²½ìš°)ã€‘", title_format
            )
            row += 2

            found_cheaper = False

            for result in results:
                # Waffle ê°€ê²© ì°¾ê¸°
                waffle_price = None
                for price in result.get("prices", []):
                    if price["seller"] == "waffle":
                        waffle_price = price.get("ìµœì¢… ê°€ê²©")
                        break

                if not isinstance(waffle_price, (int, float)):
                    continue

                # ë” ì €ë ´í•œ ê²½ìŸì‚¬ ì°¾ê¸°
                cheaper_competitors = []
                for price in result.get("prices", []):
                    if price["seller"] != "waffle":
                        comp_price = price.get("ìµœì¢… ê°€ê²©")
                        if (
                            isinstance(comp_price, (int, float))
                            and comp_price < waffle_price
                        ):
                            cheaper_competitors.append(price)

                if cheaper_competitors:
                    found_cheaper = True

                    # ì œí’ˆ ì •ë³´
                    worksheet2.write(
                        row, 0, f"ì œí’ˆëª…: {result['product_name']}", bold_format
                    )
                    row += 1
                    worksheet2.write(row, 0, f"ì œí’ˆID: {result['product_id']}")
                    row += 2

                    # í—¤ë”
                    headers = [
                        "íŒë§¤ì²˜",
                        "ìƒí’ˆ URL",
                        "ìƒí’ˆê°€ê²©",
                        "ë°°ì†¡ë¹„",
                        "ë°°ì†¡ë¹„ì—¬ë¶€",
                        "ìµœì¢…ê°€ê²©",
                        "ê°€ê²©ì°¨ì´",
                    ]
                    for col, header in enumerate(headers):
                        worksheet2.write(row, col, header, header_format)
                    row += 1

                    # Waffle ê°€ê²©
                    for price in result.get("prices", []):
                        if price["seller"] == "waffle":
                            worksheet2.write_string(row, 0, "Waffle (ìš°ë¦¬íšŒì‚¬)")
                            worksheet2.write_string(
                                row, 1, str(price.get("ìƒí’ˆ url", "N/A"))
                            )

                            wp_val = price.get("ìƒí’ˆ ê°€ê²©", "N/A")
                            if isinstance(wp_val, (int, float)):
                                worksheet2.write_number(row, 2, wp_val)
                            else:
                                worksheet2.write_string(row, 2, str(wp_val))

                            ws_val = price.get("ë°°ì†¡ë¹„", "N/A")
                            if isinstance(ws_val, (int, float)):
                                worksheet2.write_number(row, 3, ws_val)
                            else:
                                worksheet2.write_string(row, 3, str(ws_val))

                            worksheet2.write_string(
                                row, 4, str(price.get("ë°°ì†¡ë¹„ ì—¬ë¶€", "N/A"))
                            )
                            worksheet2.write_number(row, 5, waffle_price)
                            worksheet2.write_string(row, 6, "-")
                            row += 1
                            break

                    # ë” ì €ë ´í•œ ê²½ìŸì‚¬
                    for comp in cheaper_competitors:
                        comp_price = comp.get("ìµœì¢… ê°€ê²©")
                        price_diff = int(waffle_price - comp_price)

                        worksheet2.write_string(row, 0, f"ê²½ìŸì‚¬ ({comp['seller']})")
                        worksheet2.write_string(
                            row, 1, str(comp.get("ìƒí’ˆ url", "N/A"))
                        )

                        cp_val = comp.get("ìƒí’ˆ ê°€ê²©", "N/A")
                        if isinstance(cp_val, (int, float)):
                            worksheet2.write_number(row, 2, cp_val)
                        else:
                            worksheet2.write_string(row, 2, str(cp_val))

                        cs_val = comp.get("ë°°ì†¡ë¹„", "N/A")
                        if isinstance(cs_val, (int, float)):
                            worksheet2.write_number(row, 3, cs_val)
                        else:
                            worksheet2.write_string(row, 3, str(cs_val))

                        worksheet2.write_string(
                            row, 4, str(comp.get("ë°°ì†¡ë¹„ ì—¬ë¶€", "N/A"))
                        )
                        worksheet2.write_number(row, 5, comp_price)
                        worksheet2.write(
                            row, 6, f"-{price_diff}ì› ì €ë ´", bold_red_format
                        )
                        row += 1

                    row += 2  # ë¹ˆ ì¤„

            if not found_cheaper:
                worksheet2.write(row, 0, "ê°€ê²© ì—­ì „ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

            # íŒŒì¼ ë‹«ê¸° (ì¤‘ìš”!)
            workbook.close()
            return filepath

        except Exception as e:
            print(f"Excel ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            import traceback

            traceback.print_exc()
            return None

    def _add_log(self, job_id: int, level: str, message: str):
        """ë¡œê·¸ ì¶”ê°€ (UTF-8 ì¸ì½”ë”© ë³´ì¥)"""
        try:
            # ë©”ì‹œì§€ê°€ ë¬¸ìì—´ì¸ì§€ í™•ì¸í•˜ê³  UTF-8ë¡œ ì¸ì½”ë”©/ë””ì½”ë”© í™•ì¸
            if isinstance(message, bytes):
                message = message.decode("utf-8", errors="replace")
            else:
                # ë¬¸ìì—´ì„ UTF-8ë¡œ ì¸ì½”ë”©í–ˆë‹¤ê°€ ë‹¤ì‹œ ë””ì½”ë”©í•˜ì—¬ ìœ íš¨ì„± í™•ì¸
                message = message.encode("utf-8", errors="replace").decode("utf-8")

            log = CrawlingLog(job_id=job_id, level=level, message=message)
            db.session.add(log)
            db.session.commit()
        except Exception as e:
            print(f"ë¡œê·¸ ì¶”ê°€ ì‹¤íŒ¨: {str(e)}")
            db.session.rollback()


# ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
crawling_engine = CrawlingEngine()
